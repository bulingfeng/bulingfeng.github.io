---
title: "Mysql相关一些记录和总结"
subtitle: "Mysql相关一些记录和总结"
layout: post
author: "bulingfeng"
header-style: text
tags:
- mysql
---
## 关于Mysql相关总结

### 1、通俗易懂的mvcc讲解

```
https://www.cnblogs.com/jelly12345/p/14889331.html
```

### 2、mysql如何保证数据不丢失？

其实在讨论不丢失的时候，首先要定义什么是数据不丢失。我的判断是这样的：

> 如果mysql数据库提交了事务，并且没有报任何异常的情况下，这个时候如果数据库发生了各种意外而造成的数据库丢失才是真的数据库丢失。
>
> 如果是一个应用调用了数据库接口，然后在调用的过程中数据库发生了异常，这个时候数据没有写入到数据库中，这个就不能成为数据丢失。
>
> 换句话说，只要应用程序成功提交了事务，那么这个时候的数据库发生丢失才能叫数据库数据丢失。不过这里也有特殊情况，就是在事务提交的过程中，数据库发生了意外，这个时候如果redo log和bin log都把对应的数据刷到了磁盘，那么数据也照样是可恢复的。

先说结论：

> 只有redo log和binlog保证都持久化到磁盘中，这样才能最大程度的保证mysql数据不丢失。配置参数如下：
>
> > 只有在 **sync_binlog 和 innodb_flush_log_at_trx_commit 都等于1的情况下，才能保证数据不丢失。** 即
> >
> > - 写 redo log 时，每次事务提交时，都将所有`redo log` `fsync`到磁盘
> > - 写 binlog 时，每次事务提交时，`binlog` 都会执行 `fsync`到磁盘。

redo log的名词解释

> 系统崩溃重启需要按照上述内容所记录的步骤重新更新数据页，所以上述内容也被称为重做日志，即redo log.

[mysql各种日志的解释和作用](https://xie.infoq.cn/article/e59636fd19dc1963f6d017d55#:~:text=1%EF%B8%8F%E2%83%A3%20redo%20%E6%97%A5%E5%BF%97%E7%9A%84%E4%BD%9C%E7%94%A8&text=redo%20%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95%E4%BA%8B%E5%8A%A1%E6%89%A7%E8%A1%8C,%E6%8C%81%E4%B9%85%E6%80%A7%E8%BF%99%E4%B8%80%E7%89%B9%E6%80%A7%E3%80%82)

### 3、redo log 和binlog的解释

redo log和bin log都是使用的WAL（write ahead logging）技术，也就是说会先写日志再刷盘，这里的先写日志是指把日志写到内存中去，而内存有分为两部分(buffer和page cach)。

redo log的产生目的就是为了防止数据库突然发生异常而造成的数据丢失。

**关于redo log的日志写入**

下图是redo log的文件的数据结构，redo log的文件是一个环型结构（当然逻辑上是一个环型结构）;

write pos是记录当前的位置，checkpoint是要擦拭文件的位置，write pos和checkpoint之间的就是可以写入文件的内容。

redo log的写入流程是这样的：

> 当执行update语句的时候，引擎会把新数据写入到内存中，同时更新到redo log的内存日志当中，此时的redo log是出于prepare阶段，这里的prepare阶段意思是:"已经准备好了，随时可以进行日志提交"；
>
> 然后这个时候binlog的日志会写到内存中去，然后把进行提交，随后把redolog的日志状态给改成commit.

![](https://bulingfeng.com/img/mysql/image/1-redo-log-write.png)

**bin log**

> redo log是引擎端的日志，而bin log是server端的日志；

**redo log和bin log的不同**

> - redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
>
> - redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
> - redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

参考文章：

- [redolog和binlog的写入流程](https://juejin.cn/post/7019969643657822216)

### 4、索引

索引其实就是为了提高查询效率的，但是尴尬的是，你在查询数据之前，总的需要先把数据塞进去吧。而且后续还伴随着数据的删除和插入等操作，这个时候索引考虑的就不仅仅是查询的问题了，还要结合写入来进行考虑，从而得到一个相对平衡的状态。

索引的分类：

> - hash（方便插入和等值查询；但是进行范围查询的时候就比较尴尬了）
> - 有序列表（查询的时候，特别是进行连续的范围查询的时候是非常高效的，但是插入数据效率低下）
> - 树（可以平衡插入和查询的效率；比如mysql的b+树底部的数据是通过唯一索引链接起来的，范围查询更有效）
>
> 其中的树还有N叉树，这样可以让树的层数稳定在一定层数，从而减少磁盘的寻址，从而加快了查询速度。比如b+树，甚至前2层的数据都可以放内存中，因为只有最后的叶子节点才存储数据，所以非叶子节点放内存占内存比较少，从而能够大大加快查询的效率。

**索引的维护**

假设图如下：

![](https://bulingfeng.com/img/mysql/image/2-索引值维护.png)

如果数据是插入到最后的，那么这样mysql无需过多的数据维护，只需要把指针指向最后的一个叶子节点就可以了。

但是如果数据插入到中间，那么就涉及到数据的移动，并且还可能涉及到`页分裂`;也就是需要再去申请一个页然后把数据给挪过去。`页分裂`除了会造成性能的下降，还会造成数据的利用率降低，因为mysql的存储是按照页来进行存储的。

既然有`页分裂`，那么自然也会有所谓的`页合并`，也就是删除数据的时候。

> 这就解释了为何要使用自增主值来做主键，因为这样插入的时候维护数据的成本是最低的。相反如果使用uuid这类没有规则的字符串作为主键，那么对mysql来说维护的工作量真的是太大了。

#### 4.1普通索引查询过程

我们已经知道只要是`非聚蔟索引`，也就是普通的索引也会建立一个b+树，非叶子节点存的是普通索引的值（和主键一样，经过排序的），而叶子节点的内容是普通索引和主键的值。如图所示

![](https://bulingfeng.com/img/mysql/image/3-普通索引图.png)

假如我们来查询一个sql语句呢：

```sql
select * from T where k between 3 and 5;
```

```sql
create table T (
ID int primary key,
k int NOT NULL DEFAULT 0, 
s varchar(16) NOT NULL DEFAULT '',
index k(k))
engine=InnoDB;

insert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');
```

查询的过程如下：

> - 在 k 索引树上找到 k=3 的记录，取得 ID = 300；
> - 再到 ID 索引树查到 ID=300 对应的 R3；
> - 在 k 索引树取下一个值 k=5，取得 ID=500；再回到 ID 索引树查到 ID=500 对应的 R4；
> - 在 k 索引树取下一个值 k=6，不满足条件，循环结束。
>
> > 由此可见普通索引每次都要进行回表来进行查询，为什么呢？因为数据都是存在主b+树的叶子节点上。

如果想不回表查询呢？可以使用覆盖索引；使用的方式就是通过查询能够在普通索引的b+树上能够查到到自己想要的一切。例如：

```sql
select id,k from T where k between 3 and 5;
```

### 4.2最左前缀原则

> 在介绍最左前缀原则的时候，有没有想到一个问题，什么最左前缀原则能够使用到索引呢？先说结论：
>
> > 那是因为普通的索引是按照顺序来进行排好序的，所以使用最左匹配的时候只要找到了第一个，那么就通过叶子节点往后挨个查询即可。

现在有意思的事情来了，如果是创建的联合索引那么这个时候，最左前缀是用在哪个字段上才能使用到索引呢？或者准确的说才能让查询的数据更高效呢？哈哈哈

> 其实只要走索引表，其实都是利用到了索引，但是索引的数据有可能也是有很多的，如果遍历所有的索引再回表，那么效率可能还不如直接全表扫描呢。

先说结论，如果是联合索引，那么最前缀用在联合索引的第一个字段上的时候效率是最高的。

联合索引是先根据第一个字段进行排序然后建立起来b+树，如果第一个字段的值相同那么就排序第二个字段的值，以此类推。比如下图：

![](https://bulingfeng.com/img/mysql/image/4-联合索引图.png)

> 同时也解释了联合索引为何是这样建立索引的，比如建立a,b,c这样的索引，那么会建立a,ab,abc这样的三个索引，而单独的b或者bc是不会走索引的；
>
> ps:与sql的顺序无关，mysql会进行优化的。

现在有个小提问：如果有两个联合索引的值，我都想使用最左前缀原则，或者都想使用索引怎么办呢？

答：或许需要对两个值都建立索引。

### 4.3索引下推

原来没有索引下推的时候，联合索引匹配上值以后都会进行`回表`操作，而有了索引下推以后，那么会在联合索引的索引树中进行筛查一遍，从而减少了回表的次数。

```sql
select * from tuser where name like '张%' and age=10 and ismale=1;
```

上面的sql分别是没有索引下推和有索引下推的图片。

![无索引下推](https://bulingfeng.com/img/mysql/image/5-无索引下推.png)

![有索引下推](https://bulingfeng.com/img/mysql/image/6-有索引下推.png)

### 5、锁

mysql中的锁可以分为三种`库锁`、`表锁`，`行锁`，根据这些锁的名称我们就知道这些锁的用处了，但是这些锁的具体细节用法还需要记录一下；

#### 5.1库锁

> 库锁也通常称之为全局锁，也就是整个库被上了锁，然后只能读不能写，这个时候如果有正在进行的写操作或者更新的事务，DDL等语句都是无法执行的；
>
> ```sql
> Flush tables with read lock;
> ```
>
> 上面的这个命令可以让整个库只读；这个一般都用于整个库的备份，但是做法却不太好：
>
> - 如果在主库上执行，那么基本上意味着业务停摆；
> - 如果在从库上执行那么意味着不能从主库同步binlog从而导致延迟；

合理的方式在备份的那一刻执行一个事务(因为事务是一个整个库的快照)，然后再进行备份，使用mysqldump工具的`–single-transaction`参数可以满足这个要求；但是有个缺点就是这个数据库的引擎必须需要支持事务。

### 5.2表锁

表锁分为两种：`lock tables … read/write`和`MDL(metadata lock)`;

`lock tables … read/write`这种方式开始事务的线程如果是读锁，那么自己和其他线程都只能读；

如果开始的写锁，那么只有自己的这个线程能够写（读不行），其他的线程读和写都不行。

### 5.3行锁

行锁顾名思义就是对数据库中的一行进行加锁，但是这个行锁也是有条件的，需要看数据库的引擎是否支持，比如myisam引擎的修改就只支持表级别的锁，但是并不支持行级别的锁，这也是它被Innerdb锁取代的一个重要原因。

这里先说一个结论：

> update 语句产生的行界别的锁(其实delete也是)，只要在事务提交的时候，这个锁才会被释放。

既然是这样那么就会引发一个问题：

> 当同时有两个线程修改同一条数据的时候，那么谁先获取到锁，那么另一个线程就只能等待获取到锁的线程把事务给提交以后，自己才能获取到行锁；因为只要事务的提交之后，获取锁的线程才会把锁给释放掉。

这里就会引发另一个问题：

> 既然update语句是在事务提交的时候才会释放锁，那么执行update的时机，也就是说获取行锁的时机对并发性是有影响的。

例如下面例子，这三个操作的排序应该是怎样的呢？

> 1. 从顾客 A 账户余额中扣除电影票价；
> 2. 给影院 B 的账户余额增加这张电影票价；
> 3. 记录一条交易日志。

因为电影院的B账户可能是由多个顾客去操作同一条数据的，所以需要把操作电影院的操作放到最后面，从而让其他线程操作的时候等待的时间最短；所以顺序可以是3--->2--->1。

**死锁**

> 死锁顾名思义就是两个互相持有了对方的锁，从而导致双方或者多方都获取不到锁，从而造成事务变成长事务；

![死锁原理图](https://bulingfeng.com/img/mysql/image/7-死锁原理图.png)

死锁检测带来的问题

> 会大量的消耗CPU资源；因为每个事务的线程都要检查其他线程是否是死锁。比如现在有1000个并发的线程同时更新同一行数据，那么相当于死锁检测就是100w（1000*1000）;
>
> > 造成的现象就是cpu利用很高，但是每秒并没有执行几个事务。

